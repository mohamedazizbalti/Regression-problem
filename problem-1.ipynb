{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71106,"databundleVersionId":7785669,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-24T16:24:06.329941Z","iopub.execute_input":"2024-02-24T16:24:06.330618Z","iopub.status.idle":"2024-02-24T16:24:06.338857Z","shell.execute_reply.started":"2024-02-24T16:24:06.330586Z","shell.execute_reply":"2024-02-24T16:24:06.337610Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/input/dataquest-frippe-problem/sample_submission.csv\n/kaggle/input/dataquest-frippe-problem/test.csv\n/kaggle/input/dataquest-frippe-problem/data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/dataquest-frippe-problem/data.csv')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T16:20:44.143931Z","iopub.execute_input":"2024-02-24T16:20:44.144418Z","iopub.status.idle":"2024-02-24T16:20:44.313419Z","shell.execute_reply.started":"2024-02-24T16:20:44.144385Z","shell.execute_reply":"2024-02-24T16:20:44.312090Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T16:29:52.095857Z","iopub.execute_input":"2024-02-24T16:29:52.096348Z","iopub.status.idle":"2024-02-24T16:29:52.119542Z","shell.execute_reply.started":"2024-02-24T16:29:52.096314Z","shell.execute_reply":"2024-02-24T16:29:52.117945Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   ID    marka        naw3    9at3a    khochn  toul  3ordh    R   G   B   soum\n0   0  Bey&Bey  mta3 a3res  kabbout  1.081667  22.4   57.0   98  18  21   49.2\n1   1       HA       confy   sabbat  1.038333  46.4   54.0  128  23  27  180.9\n2   2      Zen       confy  maryoul  1.021667  40.8   54.0  121  22  25  143.8\n3   3  Bey&Bey       confy  maryoul  1.065000  24.8   56.0  101  18  21   54.4\n4   4   Armani      classy  kabbout  1.041667  72.0   61.0  146  26  30  345.9","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>marka</th>\n      <th>naw3</th>\n      <th>9at3a</th>\n      <th>khochn</th>\n      <th>toul</th>\n      <th>3ordh</th>\n      <th>R</th>\n      <th>G</th>\n      <th>B</th>\n      <th>soum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Bey&amp;Bey</td>\n      <td>mta3 a3res</td>\n      <td>kabbout</td>\n      <td>1.081667</td>\n      <td>22.4</td>\n      <td>57.0</td>\n      <td>98</td>\n      <td>18</td>\n      <td>21</td>\n      <td>49.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>HA</td>\n      <td>confy</td>\n      <td>sabbat</td>\n      <td>1.038333</td>\n      <td>46.4</td>\n      <td>54.0</td>\n      <td>128</td>\n      <td>23</td>\n      <td>27</td>\n      <td>180.9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Zen</td>\n      <td>confy</td>\n      <td>maryoul</td>\n      <td>1.021667</td>\n      <td>40.8</td>\n      <td>54.0</td>\n      <td>121</td>\n      <td>22</td>\n      <td>25</td>\n      <td>143.8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Bey&amp;Bey</td>\n      <td>confy</td>\n      <td>maryoul</td>\n      <td>1.065000</td>\n      <td>24.8</td>\n      <td>56.0</td>\n      <td>101</td>\n      <td>18</td>\n      <td>21</td>\n      <td>54.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Armani</td>\n      <td>classy</td>\n      <td>kabbout</td>\n      <td>1.041667</td>\n      <td>72.0</td>\n      <td>61.0</td>\n      <td>146</td>\n      <td>26</td>\n      <td>30</td>\n      <td>345.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T16:22:58.471801Z","iopub.execute_input":"2024-02-24T16:22:58.472254Z","iopub.status.idle":"2024-02-24T16:22:58.515432Z","shell.execute_reply.started":"2024-02-24T16:22:58.472222Z","shell.execute_reply":"2024-02-24T16:22:58.514134Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 48548 entries, 0 to 48547\nData columns (total 11 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   ID      48548 non-null  int64  \n 1   marka   48548 non-null  object \n 2   naw3    48548 non-null  object \n 3   9at3a   48548 non-null  object \n 4   khochn  48548 non-null  float64\n 5   toul    48548 non-null  float64\n 6   3ordh   48548 non-null  float64\n 7   R       48548 non-null  int64  \n 8   G       48548 non-null  int64  \n 9   B       48548 non-null  int64  \n 10  soum    48548 non-null  float64\ndtypes: float64(4), int64(4), object(3)\nmemory usage: 4.1+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\ndef clean(data):\n    scaler = StandardScaler()\n    label = LabelEncoder()\n    data.toul = scaler.fit_transform(np.array(data.toul).reshape(-1,1))\n    data['3ordh'] = scaler.fit_transform(np.array(data[\"3ordh\"]).reshape(-1,1))\n    data['khochn'] = scaler.fit_transform(np.array(data[\"khochn\"]).reshape(-1,1))\n    data.R = scaler.fit_transform(np.array(data.R).reshape(-1,1))\n    data.G = scaler.fit_transform(np.array(data.G).reshape(-1,1))\n    data.B = scaler.fit_transform(np.array(data.B).reshape(-1,1))\n    data.marka = label.fit_transform(data.marka)\n    data.naw3 = label.fit_transform(data.naw3)\n    data['9at3a'] = label.fit_transform(data['9at3a'])\n    X = data.drop(columns=['soum','ID'])\n    Y = data.soum\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.05, random_state=42)\n    return X_train, X_test, y_train, y_test","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:09:26.120387Z","iopub.execute_input":"2024-02-24T18:09:26.120911Z","iopub.status.idle":"2024-02-24T18:09:26.138284Z","shell.execute_reply.started":"2024-02-24T18:09:26.120861Z","shell.execute_reply":"2024-02-24T18:09:26.136644Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = clean(data)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:09:28.362842Z","iopub.execute_input":"2024-02-24T18:09:28.363548Z","iopub.status.idle":"2024-02-24T18:09:28.411804Z","shell.execute_reply.started":"2024-02-24T18:09:28.363505Z","shell.execute_reply":"2024-02-24T18:09:28.409659Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"X_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:09:29.842959Z","iopub.execute_input":"2024-02-24T18:09:29.844259Z","iopub.status.idle":"2024-02-24T18:09:29.859231Z","shell.execute_reply.started":"2024-02-24T18:09:29.844214Z","shell.execute_reply":"2024-02-24T18:09:29.857642Z"},"trusted":true},"execution_count":147,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 46120 entries, 47493 to 15795\nData columns (total 9 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   marka   46120 non-null  int64  \n 1   naw3    46120 non-null  int64  \n 2   9at3a   46120 non-null  int64  \n 3   khochn  46120 non-null  float64\n 4   toul    46120 non-null  float64\n 5   3ordh   46120 non-null  float64\n 6   R       46120 non-null  float64\n 7   G       46120 non-null  float64\n 8   B       46120 non-null  float64\ndtypes: float64(6), int64(3)\nmemory usage: 3.5 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Input\nfrom tensorflow.keras.optimizers import Adam\nmodel = Sequential([\n    Input(shape = (9,)),\n    Dense(units = 512, activation='relu'),\n    Dense(units = 256, activation='relu'),\n    Dense(units = 128, activation='relu'),\n    Dense(units = 128, activation='relu'),\n    Dense(units = 64, activation='relu'),\n    Dense(units = 32, activation='relu'),\n    Dense(units = 16, activation='relu'),\n    Dense(units = 1, activation='linear')\n])\ninitial_learning_rate = 0.001\ndecay_steps = 1000\ndecay_rate = 0.95\n\n# Create a learning rate schedule using exponential decay\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=initial_learning_rate,\n    decay_steps=decay_steps,\n    decay_rate=decay_rate,\n    staircase=False)\n\n# Create the Adam optimizer with the learning rate schedule\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\nmodel.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae']) \nmodel.fit(X_train,y_train,batch_size=128,validation_data=(X_test,y_test),epochs=70)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:43:08.684205Z","iopub.execute_input":"2024-02-24T17:43:08.684727Z","iopub.status.idle":"2024-02-24T17:43:14.068259Z","shell.execute_reply.started":"2024-02-24T17:43:08.684690Z","shell.execute_reply":"2024-02-24T17:43:14.066398Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Epoch 1/70\n304/304 [==============================] - 4s 9ms/step - loss: 51818.3242 - mae: 124.9101 - val_loss: 20730.6406 - val_mae: 86.9938\nEpoch 2/70\n 94/304 [========>.....................] - ETA: 1s - loss: 19371.8320 - mae: 81.9383","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[78], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlr_schedule)\n\u001b[1;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[0;32m---> 29\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score\nmodel1 = XGBRegressor(n_estimators=1700, max_depth=8, eta= 0.007,booster='dart')\nmodel1.fit(X_train,y_train)\npredictions = model1.predict(X_test)\nr2 = r2_score(y_test,predictions)\nprint(r2)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:30:37.253650Z","iopub.execute_input":"2024-02-24T18:30:37.255029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:15:10.459113Z","iopub.execute_input":"2024-02-24T17:15:10.459556Z","iopub.status.idle":"2024-02-24T17:15:10.468491Z","shell.execute_reply.started":"2024-02-24T17:15:10.459519Z","shell.execute_reply":"2024-02-24T17:15:10.467090Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"<keras.src.engine.sequential.Sequential at 0x7a041b46ac50>"},"metadata":{}}]},{"cell_type":"code","source":"predictions = model.predict(X_test)\nr2 = r2_score(y_test,predictions)\nprint(r2)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T17:42:50.623364Z","iopub.execute_input":"2024-02-24T17:42:50.623948Z","iopub.status.idle":"2024-02-24T17:42:51.610657Z","shell.execute_reply.started":"2024-02-24T17:42:50.623902Z","shell.execute_reply":"2024-02-24T17:42:51.609040Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"304/304 [==============================] - 1s 2ms/step\n0.9800161623700591\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\ndef clean_onehot(data):\n    scaler = StandardScaler()\n    encoder = OneHotEncoder()\n    \n    # Scale numerical features\n    data.toul = scaler.fit_transform(np.array(data.toul).reshape(-1,1))\n    data['3ordh'] = scaler.fit_transform(np.array(data[\"3ordh\"]).reshape(-1,1))\n    data['khochn'] = scaler.fit_transform(np.array(data[\"khochn\"]).reshape(-1,1))\n    data.R = scaler.fit_transform(np.array(data.R).reshape(-1,1))\n    data.G = scaler.fit_transform(np.array(data.G).reshape(-1,1))\n    data.B = scaler.fit_transform(np.array(data.B).reshape(-1,1))\n    \n    # Encode categorical features with OneHotEncoder\n    marka_encoded = encoder.fit_transform(np.array(data.marka).reshape(-1, 1))\n    naw3_encoded = encoder.fit_transform(np.array(data.naw3).reshape(-1, 1))\n    hat3a_encoded = encoder.fit_transform(np.array(data['9at3a']).reshape(-1, 1))\n    \n    # Convert sparse matrices to arrays and concatenate\n    encoded_features = np.concatenate([marka_encoded.toarray(), naw3_encoded.toarray(), hat3a_encoded.toarray()], axis=1)\n    \n    # Create DataFrame for encoded features\n    encoded_df = pd.DataFrame(encoded_features, columns=['marka_' + str(i) for i in range(marka_encoded.shape[1])] + \n                                                    ['naw3_' + str(i) for i in range(naw3_encoded.shape[1])] +\n                                                    ['hat3a_' + str(i) for i in range(hat3a_encoded.shape[1])])\n    \n    # Concatenate numerical and encoded categorical features\n    data_encoded = pd.concat([data.drop(columns=['marka', 'naw3', '9at3a']), encoded_df], axis=1)\n    \n    return data_encoded","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:10:07.034287Z","iopub.execute_input":"2024-02-24T18:10:07.035404Z","iopub.status.idle":"2024-02-24T18:10:07.053057Z","shell.execute_reply.started":"2024-02-24T18:10:07.035359Z","shell.execute_reply":"2024-02-24T18:10:07.051559Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"data_e = clean_onehot(data)\nX = data_e.drop(columns=['soum'])\nY = data_e.soum\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:10:12.100564Z","iopub.execute_input":"2024-02-24T18:10:12.101149Z","iopub.status.idle":"2024-02-24T18:10:12.174118Z","shell.execute_reply.started":"2024-02-24T18:10:12.101107Z","shell.execute_reply":"2024-02-24T18:10:12.172522Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"def clean_test(data):\n    scaler = StandardScaler()\n    label = LabelEncoder()\n    data.toul = scaler.fit_transform(np.array(data.toul).reshape(-1,1))\n    data['3ordh'] = scaler.fit_transform(np.array(data[\"3ordh\"]).reshape(-1,1))\n    data['khochn'] = scaler.fit_transform(np.array(data[\"khochn\"]).reshape(-1,1))\n    data.R = scaler.fit_transform(np.array(data.R).reshape(-1,1))\n    data.G = scaler.fit_transform(np.array(data.G).reshape(-1,1))\n    data.B = scaler.fit_transform(np.array(data.B).reshape(-1,1))\n    data.marka = label.fit_transform(data.marka)\n    data.naw3 = label.fit_transform(data.naw3)\n    data['9at3a'] = label.fit_transform(data['9at3a'])\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:09:08.013283Z","iopub.execute_input":"2024-02-24T18:09:08.013770Z","iopub.status.idle":"2024-02-24T18:09:08.024340Z","shell.execute_reply.started":"2024-02-24T18:09:08.013738Z","shell.execute_reply":"2024-02-24T18:09:08.023262Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/dataquest-frippe-problem/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:21:23.423078Z","iopub.execute_input":"2024-02-24T18:21:23.423504Z","iopub.status.idle":"2024-02-24T18:21:23.443315Z","shell.execute_reply.started":"2024-02-24T18:21:23.423476Z","shell.execute_reply":"2024-02-24T18:21:23.441709Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"test_clean = clean_onehot(test)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:24:14.482593Z","iopub.execute_input":"2024-02-24T18:24:14.483132Z","iopub.status.idle":"2024-02-24T18:24:14.504311Z","shell.execute_reply.started":"2024-02-24T18:24:14.483088Z","shell.execute_reply":"2024-02-24T18:24:14.503135Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"code","source":"predictions = model1.predict(test_clean.drop(columns=['ID']))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:24:26.191390Z","iopub.execute_input":"2024-02-24T18:24:26.191829Z","iopub.status.idle":"2024-02-24T18:24:26.390764Z","shell.execute_reply.started":"2024-02-24T18:24:26.191799Z","shell.execute_reply":"2024-02-24T18:24:26.389663Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"predictions_df = pd.DataFrame({'ID':test_clean.ID , 'Predictions': predictions})","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:24:29.073985Z","iopub.execute_input":"2024-02-24T18:24:29.074441Z","iopub.status.idle":"2024-02-24T18:24:29.081468Z","shell.execute_reply.started":"2024-02-24T18:24:29.074411Z","shell.execute_reply":"2024-02-24T18:24:29.080049Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"predictions_df","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:24:30.401625Z","iopub.execute_input":"2024-02-24T18:24:30.402072Z","iopub.status.idle":"2024-02-24T18:24:30.415677Z","shell.execute_reply.started":"2024-02-24T18:24:30.402042Z","shell.execute_reply":"2024-02-24T18:24:30.414476Z"},"trusted":true},"execution_count":192,"outputs":[{"execution_count":192,"output_type":"execute_result","data":{"text/plain":"        ID  Predictions\n0        0    96.368706\n1        1   228.078690\n2        2   376.805969\n3        3    61.107487\n4        4   370.702881\n...    ...          ...\n5390  5390   735.109253\n5391  5391   861.446350\n5392  5392   109.253494\n5393  5393  1351.632690\n5394  5394  1290.900635\n\n[5395 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>96.368706</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>228.078690</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>376.805969</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>61.107487</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>370.702881</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5390</th>\n      <td>5390</td>\n      <td>735.109253</td>\n    </tr>\n    <tr>\n      <th>5391</th>\n      <td>5391</td>\n      <td>861.446350</td>\n    </tr>\n    <tr>\n      <th>5392</th>\n      <td>5392</td>\n      <td>109.253494</td>\n    </tr>\n    <tr>\n      <th>5393</th>\n      <td>5393</td>\n      <td>1351.632690</td>\n    </tr>\n    <tr>\n      <th>5394</th>\n      <td>5394</td>\n      <td>1290.900635</td>\n    </tr>\n  </tbody>\n</table>\n<p>5395 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictions_df.to_csv('submission3.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:25:05.989906Z","iopub.execute_input":"2024-02-24T18:25:05.990445Z","iopub.status.idle":"2024-02-24T18:25:06.013510Z","shell.execute_reply.started":"2024-02-24T18:25:05.990410Z","shell.execute_reply":"2024-02-24T18:25:06.012195Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"data_enc = clean_onehot(data)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:13:20.954218Z","iopub.execute_input":"2024-02-24T18:13:20.955064Z","iopub.status.idle":"2024-02-24T18:13:21.008924Z","shell.execute_reply.started":"2024-02-24T18:13:20.955019Z","shell.execute_reply":"2024-02-24T18:13:21.007319Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"X = data_enc.drop(columns=['ID','soum'])\nY = data_enc.soum\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.05, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:13:24.112116Z","iopub.execute_input":"2024-02-24T18:13:24.112958Z","iopub.status.idle":"2024-02-24T18:13:24.133442Z","shell.execute_reply.started":"2024-02-24T18:13:24.112912Z","shell.execute_reply":"2024-02-24T18:13:24.132346Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}